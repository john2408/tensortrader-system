{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from os.path import join\n",
    "from os import getcwd\n",
    "from pathlib import Path\n",
    "from sys import path\n",
    "\n",
    "full_path = getcwd()\n",
    "functions_path = join( Path(full_path).parents[0].parents[0] )\n",
    "path.append( functions_path  )\n",
    "\n",
    "from functions.feature_engineering import FEATURES_CONFIG_IDS\n",
    "import functions.feature_engineering as fe\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "CONF = yaml.safe_load(Path('config.yml').read_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'kind': 'ema', 'length': 3},\n",
       " {'kind': 'ema', 'length': 15},\n",
       " {'kind': 'ema', 'length': 60},\n",
       " {'kind': 'bbands', 'length': 20},\n",
       " {'kind': 'bbands', 'length': 20},\n",
       " {'kind': 'macd', 'fast': 8, 'slow': 21},\n",
       " {'kind': 'rsi', 'length': 14},\n",
       " {'kind': 'atr', 'length': 14},\n",
       " {'kind': 'pdist'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONF['Feature_Engineering'][1]['ta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Feature_Engineering': {1: {'ta': [{'kind': 'ema', 'length': 3},\n",
       "    {'kind': 'ema', 'length': 15},\n",
       "    {'kind': 'ema', 'length': 60},\n",
       "    {'kind': 'bbands', 'length': 20},\n",
       "    {'kind': 'bbands', 'length': 20},\n",
       "    {'kind': 'macd', 'fast': 8, 'slow': 21},\n",
       "    {'kind': 'rsi', 'length': 14},\n",
       "    {'kind': 'atr', 'length': 14},\n",
       "    {'kind': 'pdist'}],\n",
       "   'include_lags': True,\n",
       "   'lags': [1, 3, 5, 15, 30],\n",
       "   'ref_variable_lags': ['Close'],\n",
       "   'drop_lags': False,\n",
       "   'Volume_Features': True,\n",
       "   'Volume_Windows': [5, 60],\n",
       "   'Volume_Returns': True,\n",
       "   'Volume_Returns_lags': [5, 15],\n",
       "   'Volume_Returns_binary': True,\n",
       "   'EntryPrice_PrevClose': False,\n",
       "   'lags_diff': [1, 15, 30, 60],\n",
       "   'binary_lags': True,\n",
       "   'Return_Features': True,\n",
       "   'return_lags': [1, 5, 15, 60, 240],\n",
       "   'Momentum_Features': False,\n",
       "   'use_prob_features': True,\n",
       "   'probability_features': ['entry_type', 'risk_type'],\n",
       "   'Prob_Features_Windows': [2, 6]}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description \n",
    "The goal is to generate features to be able to predict the variable risk_type and entry_type. \n",
    "\n",
    "This codes produces different feature for different scenario. Using the global variable FEATURES_CONFIG_IDS different feature scenarios can be selected. \n",
    "\n",
    "Select the forecast horizon fh, then the column risk_type and entry_type will be shifted fh steps to the future. This will be the target variables for the ML Models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_folder = '/media/john/Data/Tensor_Invest_Fund/data/Cryptos/TBM/'\n",
    "\n",
    "storage_folder = '/mnt/Data/Tensor_Invest_Fund/data/Cryptos/TBM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tripe_Barrier_Method_ADAUSDT_ptsl_1-1_vb_15m.parquet',\n",
       " 'Tripe_Barrier_Method_ADAUSDT_ptsl_2-1_vb_15m.parquet',\n",
       " 'Tripe_Barrier_Method_ADAUSDT_ptsl_2-2_vb_15m.parquet']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.join(storage_folder, 'ADAUSDT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_id = 1\n",
    "strategy = '1-1_vb_15m' # '2-1_vb_15m' or 2-2_vb_15m\n",
    "\n",
    "SYMBOLS = ['ADAUSDT',\n",
    " 'BNBBTC',\n",
    " 'BNBUSDT',\n",
    " 'BTCUSDT',\n",
    " 'DOGEUSDT',\n",
    " 'EOSUSDT',\n",
    " 'ETCUSDT',\n",
    " 'ETHUSDT',\n",
    " 'IOTAUSDT',\n",
    " 'LTCUSDT',\n",
    " 'MKRUSDT',\n",
    " 'TRXUSDT',\n",
    " 'XLMUSDT',\n",
    " 'XMRBTC']\n",
    "\n",
    "SYMBOLS = ['ADAUSDT',\n",
    " 'BNBBTC',\n",
    " 'BNBUSDT',\n",
    " 'ETHUSDT']\n",
    "\n",
    "input_folder_db = storage_folder\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for ticker in SYMBOLS:\n",
    "\n",
    "    data_path = f'{ticker}/Tripe_Barrier_Method_{ticker}_ptsl_{strategy}.parquet'\n",
    "\n",
    "    dfs.append(pd.read_parquet(os.path.join(input_folder_db, data_path)))\n",
    "\n",
    "data = pd.concat(dfs, ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1050253 entries, 0 to 1050252\n",
      "Data columns (total 19 columns):\n",
      " #   Column                        Non-Null Count    Dtype         \n",
      "---  ------                        --------------    -----         \n",
      " 0   Open Time                     1050253 non-null  int64         \n",
      " 1   Open                          1050253 non-null  float64       \n",
      " 2   High                          1050253 non-null  float64       \n",
      " 3   Low                           1050253 non-null  float64       \n",
      " 4   Close                         1050253 non-null  float64       \n",
      " 5   Volume                        1050253 non-null  float64       \n",
      " 6   Clos Time                     1050253 non-null  int64         \n",
      " 7   Quote Asset Volume            1050253 non-null  float64       \n",
      " 8   Number of Trades              1050253 non-null  int32         \n",
      " 9   Taker Buy Base Asset Volume   1050253 non-null  float64       \n",
      " 10  Taker Buy Quote Asset Volume  1050253 non-null  float64       \n",
      " 11  Ignore                        1050253 non-null  object        \n",
      " 12  Date                          1050253 non-null  datetime64[ns]\n",
      " 13  Year                          1050253 non-null  int32         \n",
      " 14  Ticker                        1050253 non-null  object        \n",
      " 15  max_trades                    1050253 non-null  int32         \n",
      " 16  threshold                     1050253 non-null  float64       \n",
      " 17  t1                            1050253 non-null  datetime64[ns]\n",
      " 18  label                         1050253 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(9), int32(3), int64(3), object(2)\n",
      "memory usage: 140.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2022-03-25 14:59:00'), Timestamp('2021-09-01 01:02:00'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Date'].max(), data['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADAUSDT', 'BNBBTC', 'BNBUSDT', 'ETHUSDT'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Ticker'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Indicators Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://github.com/twopirllc/pandas-ta/blob/main/examples/PandasTA_Strategy_Examples.ipynb\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for ticker in SYMBOLS:\n",
    "\n",
    "    _df = data[data['Ticker'] == ticker].copy()\n",
    "\n",
    "    MNQ_strategy = ta.Strategy(\n",
    "        name=\"MNQ Strategy\",\n",
    "        description=\"Non Multiprocessing Strategy by rename Columns\",\n",
    "        ta = CONF['Feature_Engineering'][feature_id]['ta']\n",
    "    )\n",
    "\n",
    "\n",
    "    #data.set_index(['datetime'], inplace  = True)\n",
    "    # Run it\n",
    "    _df.ta.strategy(MNQ_strategy)\n",
    "\n",
    "    dfs.append(_df)\n",
    "\n",
    "new_data = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating lags for ticker ADAUSDT\n",
      "Calculating lags for ticker BNBBTC\n",
      "Calculating lags for ticker BNBUSDT\n",
      "Calculating lags for ticker ETHUSDT\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "if CONF['Feature_Engineering'][feature_id]['include_lags']:\n",
    "\n",
    "    for ticker in SYMBOLS:\n",
    "\n",
    "        print(\"Calculating lags for ticker\", ticker)\n",
    "\n",
    "        _df = data[data['Ticker'] == ticker].copy()\n",
    "\n",
    "        n_lags = CONF['Feature_Engineering'][feature_id]['lags']\n",
    "        ref_variable_lags = CONF['Feature_Engineering'][feature_id]['ref_variable_lags']\n",
    "        drop = CONF['Feature_Engineering'][feature_id]['drop_lags']\n",
    "\n",
    "        for ref_variable in ref_variable_lags:\n",
    "\n",
    "            lags_features = []\n",
    "\n",
    "            if n_lags is not None:\n",
    "                for lag in n_lags:\n",
    "\n",
    "                    columns_name = f'{ref_variable}_lag_{lag}'\n",
    "\n",
    "                    _df.loc[:,columns_name] = _df[ref_variable].shift(lag)\n",
    "\n",
    "                    lags_features.append(columns_name) \n",
    "\n",
    "        dfs.append(_df)\n",
    "\n",
    "    new_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "data = new_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entry Price - Previous Close Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONF['Feature_Engineering'][feature_id]['EntryPrice_PrevClose']: \n",
    "\n",
    "    lags_diff = CONF['Feature_Engineering'][feature_id]['lags_diff']\n",
    "    target_variable = 'Entry_PrevClose_diff'\n",
    "    short= 5\n",
    "    long = 15\n",
    "    variables = ['sma', 'std', 'bbands']\n",
    "    drop_columns = []\n",
    "\n",
    "    for lag in lags_diff:\n",
    "\n",
    "        target_variable_name = f'{target_variable}_{lag}'\n",
    "\n",
    "        data[target_variable_name] = data['entry_market'] - data[f'{ref_variable_lags}_lag_{lag}']\n",
    "\n",
    "        data = fe.calculate_rolling_features(data, target_variable_name, short, long, variables, drop_columns, drop_target_variable = True )\n",
    "\n",
    "        \n",
    "if drop:\n",
    "    data.drop(columns = lags_features, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Time', 'Open', 'High', 'Low', 'Close', 'Vol', 'year', 'month',\n",
       "       'day', 'hour', 'minute', 'ticker', 'datetime', 'Time_tuple',\n",
       "       'entry_market', 'target', 'stop', 'entry_type', 'risk_type', 'NATR_5',\n",
       "       'NATR_60'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(data: pd.DataFrame, variable: str, lags: list, binary_lags: bool, date_col : str = 'Date', outlier_cutoff : float = 0.01):\n",
    "    \"\"\"Calculate returns base of a target variable. \n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): _description_\n",
    "        variable (str): _description_\n",
    "        lags (list): _description_\n",
    "        binary_lags (bool): _description_\n",
    "        date_col (str, optional): _description_. Defaults to 'Date'.\n",
    "        outlier_cutoff (float, optional): \n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    returns = []\n",
    "\n",
    "    for lag in lags:\n",
    "        if binary_lags:\n",
    "            _return = returns.append(data.set_index([date_col])[variable]\n",
    "                        .sort_index() # Sort by Date\n",
    "                        .pct_change(lag) # Calculate percentage change of the respective lag value\n",
    "                        .pipe(lambda x: x.clip(lower=x.quantile(outlier_cutoff),\n",
    "                                                upper=x.quantile(1-outlier_cutoff))) # Cutoff outliers\n",
    "                        .add(1) # add 1 to the returns\n",
    "                        .pow(1/lag) # apply n root for n = lag\n",
    "                        .sub(1) #substract 1\n",
    "                        .apply(lambda x: 1 if x > 0 else 0)\n",
    "                        .to_frame(f'{variable}_return_{lag}m')\n",
    "                        \n",
    "                        )\n",
    "\n",
    "        else:\n",
    "            _return = returns.append(data.set_index([date_col])[variable]\n",
    "                    .sort_index() # Sort by Date\n",
    "                    .pct_change(lag) # Calculate percentage change of the respective lag value\n",
    "                    .pipe(lambda x: x.clip(lower=x.quantile(outlier_cutoff),\n",
    "                                            upper=x.quantile(1-outlier_cutoff))) # Cutoff outliers\n",
    "                    .add(1) # add 1 to the returns\n",
    "                    .pow(1/lag) # apply n root for n = lag\n",
    "                    .sub(1) #substract 1\n",
    "                    .to_frame(f'{variable}_return_{lag}m')\n",
    "                    \n",
    "                )\n",
    "\n",
    "    returns.append(_return)\n",
    "        \n",
    "    returns = pd.concat(returns, axis = 1)\n",
    "    #returns.info(null_counts=True)\n",
    "\n",
    "    data = data.set_index([date_col]).join(returns).dropna()\n",
    "    data.reset_index(inplace = True)\n",
    "\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating returns for ticker ADAUSDT\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 296038 entries, 2021-09-01 01:02:00 to 2022-03-25 14:59:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Close_return_1m    296037 non-null  float64\n",
      " 1   Close_return_5m    296033 non-null  float64\n",
      " 2   Close_return_15m   296023 non-null  float64\n",
      " 3   Close_return_60m   295978 non-null  float64\n",
      " 4   Close_return_240m  295798 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 13.6 MB\n",
      "Calculating returns for ticker BNBBTC\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 162139 entries, 2021-12-03 00:41:00 to 2022-03-25 14:59:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Close_return_1m    162138 non-null  float64\n",
      " 1   Close_return_5m    162134 non-null  float64\n",
      " 2   Close_return_15m   162124 non-null  float64\n",
      " 3   Close_return_60m   162079 non-null  float64\n",
      " 4   Close_return_240m  161899 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 7.4 MB\n",
      "Calculating returns for ticker BNBUSDT\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 296038 entries, 2021-09-01 01:02:00 to 2022-03-25 14:59:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Close_return_1m    296037 non-null  float64\n",
      " 1   Close_return_5m    296033 non-null  float64\n",
      " 2   Close_return_15m   296023 non-null  float64\n",
      " 3   Close_return_60m   295978 non-null  float64\n",
      " 4   Close_return_240m  295798 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 13.6 MB\n",
      "Calculating returns for ticker ETHUSDT\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 296038 entries, 2021-09-01 01:02:00 to 2022-03-25 14:59:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Close_return_1m    296037 non-null  float64\n",
      " 1   Close_return_5m    296033 non-null  float64\n",
      " 2   Close_return_15m   296023 non-null  float64\n",
      " 3   Close_return_60m   295978 non-null  float64\n",
      " 4   Close_return_240m  295798 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 13.6 MB\n"
     ]
    }
   ],
   "source": [
    "if CONF['Feature_Engineering'][feature_id]['Return_Features']:\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for ticker in SYMBOLS:\n",
    "\n",
    "        print(\"Calculating returns for ticker\", ticker)\n",
    "\n",
    "        _df = data[data['Ticker'] == ticker].copy()\n",
    "\n",
    "        outlier_cutoff = 0.01\n",
    "        lags = CONF['Feature_Engineering'][feature_id]['return_lags'] \n",
    "        binary_lags = CONF['Feature_Engineering'][feature_id]['binary_lags'] \n",
    "        \n",
    "        variable = 'Close'\n",
    "\n",
    "        _df = calculate_returns(_df, variable, lags, binary_lags)\n",
    "\n",
    "        dfs.append(_df)\n",
    "\n",
    "    new_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    data = new_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FEATURES_CONFIG_IDS[feature_id]['Return_Features']:\n",
    "    if FEATURES_CONFIG_IDS[feature_id]['Momentum_Features']:\n",
    "\n",
    "        dfs = []\n",
    "\n",
    "        for ticker in SYMBOLS:\n",
    "\n",
    "            print(\"Calculating momemtum for ticker\", ticker)\n",
    "\n",
    "            _df = data[data['Ticker'] == ticker].copy()\n",
    "\n",
    "            for lag in lags:\n",
    "                if lag > lags[0]:\n",
    "                    _df['momentum_{}_{}'.format( lags[0], lag)] = data[f'return_{lag}m'].sub(data['return_{}m'.format(lags[0])])\n",
    "                if lag > lags[1]:\n",
    "                    _df['momentum_{}_{}'.format( lags[1], lag)] = data[f'return_{lag}m'].sub(data['return_{}m'.format(lags[1])])\n",
    "\n",
    "        \n",
    "            dfs.append(_df)\n",
    "\n",
    "        new_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        data = new_data.copy()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 38417 entries, 2021-06-01 16:10:00 to 2021-10-14 21:44:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   Vol_return_5m   38417 non-null  int64\n",
      " 1   Vol_return_15m  38417 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 900.4 KB\n"
     ]
    }
   ],
   "source": [
    "if FEATURES_CONFIG_IDS[feature_id]['Volume_Features']:\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for ticker in SYMBOLS:\n",
    "\n",
    "        print(\"Calculating momemtum for ticker\", ticker)\n",
    "\n",
    "        _df = data[data['Ticker'] == ticker].copy()\n",
    "\n",
    "        short = FEATURES_CONFIG_IDS[feature_id]['Volume_Windows'][0]\n",
    "        long = FEATURES_CONFIG_IDS[feature_id]['Volume_Windows'][1]\n",
    "        drop_columns = []\n",
    "\n",
    "        target_variable = 'Volume'\n",
    "        variables = ['sma', 'std']\n",
    "\n",
    "        _df = fe.calculate_rolling_features(_df, target_variable, short, long, variables, drop_columns, drop_target_variable=False )\n",
    "\n",
    "        dfs.append(_df)\n",
    "        \n",
    "    new_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    data = new_data.copy()  \n",
    "\n",
    "if FEATURES_CONFIG_IDS[feature_id]['Volume_Returns']:\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for ticker in SYMBOLS:\n",
    "\n",
    "        print(\"Calculating momemtum for ticker\", ticker)\n",
    "\n",
    "        _df = data[data['Ticker'] == ticker].copy()\n",
    "\n",
    "        lags = FEATURES_CONFIG_IDS[feature_id]['Volume_Returns_lags'] \n",
    "        binary_lags = FEATURES_CONFIG_IDS[feature_id]['Volume_Returns_binary'] \n",
    "        \n",
    "        variable = 'Volume'\n",
    "\n",
    "        _df = calculate_returns(_df, variable, lags, binary_lags)\n",
    "\n",
    "\n",
    "        dfs.append(_df)\n",
    "        \n",
    "    new_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    data = new_data.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'Date', 'Time', 'Open', 'High', 'Low', 'Close', 'Vol',\n",
       "       'year', 'month', 'day', 'hour', 'minute', 'ticker', 'Time_tuple',\n",
       "       'entry_market', 'target', 'stop', 'entry_type', 'risk_type', 'NATR_5',\n",
       "       'NATR_60', 'Close_return_1m', 'Close_return_5m', 'Close_return_15m',\n",
       "       'Close_return_60m', 'Close_return_240m', 'Vol_sma_5', 'Vol_sma_60',\n",
       "       'Vol_std_5', 'Vol_std_60', 'Vol_return_5m', 'Vol_return_15m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fe.build_fourier_time_features(data, time_levels = ['month', 'day', 'hour', 'minute'], max_levels = [12, 30, 24, 60], drop_columns = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Distribution Features of Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable canbe entry_type or risk_type\n",
    "short = FEATURES_CONFIG_IDS[feature_id]['Prob_Features_Windows'][0]\n",
    "long = FEATURES_CONFIG_IDS[feature_id]['Prob_Features_Windows'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only entry_type, or only risk_type or both\n",
    "\n",
    "probability_features = FEATURES_CONFIG_IDS[feature_id]['probability_features']\n",
    "\n",
    "if FEATURES_CONFIG_IDS[feature_id]['use_prob_features']:\n",
    "    for target_variable in probability_features:\n",
    "\n",
    "        daily_distribution = fe.calculate_prob_distribution_features(data = data, \n",
    "                                                target_variable =target_variable ,\n",
    "                                                short = short, \n",
    "                                                long = long)\n",
    "\n",
    "        data = pd.merge(data, daily_distribution[['Date',\n",
    "                                                f'{target_variable}_sma_{short}',\n",
    "                                                f'{target_variable}_sma_{long}',\n",
    "                                                f'{target_variable}_std_{short}',\n",
    "                                                f'{target_variable}_std_{long}',\n",
    "                                                f'{target_variable}_cv_{short}' ]], \n",
    "                                                on = ['Date'], \n",
    "                                                how = 'left').copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (daily_distribution[daily_distribution[target_variable] == 1]\n",
    "# .plot(x = 'Date', \n",
    "# y = ['distribution',f'{target_variable}_sma_{short}', f'{target_variable}_cv_{short}'] , figsize = (15,10) )) #,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_id == 4:\n",
    "\n",
    "    #short = 4\n",
    "    #long = 15\n",
    "\n",
    "    data['Low_diff'] = data['Low'] - data['stop']\n",
    "\n",
    "    # data['Low_diff'] = scaler.fit(np.array(data['Low_diff']).reshape(-1, 1))\n",
    "\n",
    "    # data[f'Low_diff_sma_{short}'] = (data['Low_diff'].rolling(window = short, closed = 'left')\n",
    "    #                                                     .mean().fillna(method = 'backfill'))\n",
    "    \n",
    "    # data[f'Low_diff_sma_{long}'] = (data['Low_diff'].rolling(window = long, closed = 'left')\n",
    "    #                                                     .mean().fillna(method = 'backfill'))\n",
    "\n",
    "\n",
    "    # data.drop(columns = [f'Low_diff_std_{short}', \n",
    "    #                     f'Low_diff_std_{long}'], inplace = True )\n",
    "\n",
    "\n",
    "if feature_id == 5:\n",
    "\n",
    "    data[f'Low_sma_{short}'] = (data['Low'].rolling(window = short, closed = 'left')\n",
    "                                                        .mean().fillna(method = 'backfill'))\n",
    "    \n",
    "    data[f'Low_sma_{long}'] = (data['Low'].rolling(window = long, closed = 'left')\n",
    "                                                        .mean().fillna(method = 'backfill'))\n",
    "\n",
    "    data[f'Low_std_{short}'] = (data['Low'].rolling(window = short, closed = 'left')\n",
    "                                                        .std().fillna(method = 'backfill'))\n",
    "    \n",
    "    data[f'Low_std_{long}'] = (data['Low'].rolling(window = long, closed = 'left')\n",
    "                                                        .std().fillna(method = 'backfill'))\n",
    "\n",
    "    data[f'Low_cv_{short}'] = (data[f'Low_std_{short}'] /\n",
    "                                        data[f'Low_sma_{short}'])\n",
    "\n",
    "    data[f'Low_cv_{long}'] = (data[f'Low_std_{short}'] / \n",
    "                                        data[f'Low_sma_{short}'])\n",
    "\n",
    "\n",
    "    data.drop(columns = [f'Low_std_{short}', \n",
    "                        f'Low_std_{long}'], inplace = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "\n",
    "# Improve Feature Engineering on Risk Forecast\n",
    "# Daily Risk Forecast Distribution \n",
    "# Hourly Risk Forecast Distribution \n",
    "\n",
    "# # Hourly Risk Distribution\n",
    "# data['hour'] = data['datetime'].dt.hour\n",
    "\n",
    "# hourly_distribution = (data.groupby(['hour'])['risk_type'].value_counts()\n",
    "#                     .to_frame()\n",
    "#                     .rename(columns = {'risk_type': 'counts'})\n",
    "#                     .reset_index())\n",
    "\n",
    "# hourly_distribution['hourly_sum'] = hourly_distribution.groupby(['hour'])['counts'].transform(np.sum)\n",
    "\n",
    "# hourly_distribution['distribution'] = np.round( hourly_distribution['counts'] / hourly_distribution['hourly_sum'] , 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Forecast Horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'Date', 'Time', 'Open', 'High', 'Low', 'Close', 'Vol',\n",
       "       'year', 'ticker', 'Time_tuple', 'entry_market', 'target', 'stop',\n",
       "       'entry_type', 'risk_type', 'NATR_5', 'NATR_60', 'Close_return_1m',\n",
       "       'Close_return_5m', 'Close_return_15m', 'Close_return_60m',\n",
       "       'Close_return_240m', 'Vol_sma_5', 'Vol_sma_60', 'Vol_std_5',\n",
       "       'Vol_std_60', 'Vol_return_5m', 'Vol_return_15m', 'month_sin',\n",
       "       'month_cos', 'day_sin', 'day_cos', 'hour_sin', 'hour_cos', 'minute_sin',\n",
       "       'minute_cos', 'entry_type_sma_2', 'entry_type_sma_6',\n",
       "       'entry_type_std_2', 'entry_type_std_6', 'entry_type_cv_2',\n",
       "       'risk_type_sma_2', 'risk_type_sma_6', 'risk_type_std_2',\n",
       "       'risk_type_std_6', 'risk_type_cv_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_variable = FEATURES_CONFIG_IDS[feature_id].get('forecast_variable', None)\n",
    "\n",
    "if forecast_variable is not None:\n",
    "\n",
    "    fh = FEATURES_CONFIG_IDS[feature_id].get('forecast_shift')\n",
    "\n",
    "    data.loc[:,f'{forecast_variable}_target'] = ((data[\"Close\"].shift(-fh)).sub(data[\"Close\"]))\n",
    "    data.loc[:,f'{forecast_variable}_target'] = data[target_variable].apply(lambda x: 0 if x <= 0 else 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['return_5m_target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_db ='../../data/Model2'\n",
    "sub_experiment_type = f'feature_config{feature_id}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/Model2\\Feature_Engineering\\NQ\\Model2_Feature_Engineering__feature_config16_t10-r10_w5.parquet\n"
     ]
    }
   ],
   "source": [
    "output_location = os.path.join(output_folder_db, 'Feature_Engineering',  'NQ', \n",
    "                            ('Model2_Feature_Engineering__{}_{}.parquet'\n",
    "                            .format( sub_experiment_type, strategy)))\n",
    "\n",
    "print(output_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet(output_location , engine = 'fastparquet', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d6665af479ab98ef4acca01ca45d4d57a52903c594eb1765faf156f4475f423"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('AlgoTrading': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
